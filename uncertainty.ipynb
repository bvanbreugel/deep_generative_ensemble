{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bv292/miniconda/envs/test_env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "from synthcity.metrics.eval_performance import (\n",
    "    PerformanceEvaluatorMLP,\n",
    "    PerformanceEvaluatorXGB,\n",
    ")\n",
    "from synthcity.utils import reproducibility\n",
    "from synthcity.plugins import Plugins\n",
    "import synthcity.logger as log\n",
    "from synthcity.plugins.core.dataloader import GenericDataLoader\n",
    "from DGE_utils import metric_different_datasets, mean_across_pandas, add_std, get_folder_names\n",
    "\n",
    "reproducibility.clear_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "Plugins(categories=[\"generic\"]).list()\n",
    "\n",
    "assert device.type == 'cuda'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DGE_data import get_real_and_synthetic\n",
    "\n",
    "# let's restrict ourselves to classification datasets\n",
    "datasets = ['moons', 'circles', #'gaussian',\n",
    "            'adult',  'seer']\n",
    "# ['moons', 'circles','cal_housing', 'adult', 'diabetes', 'breast_cancer',  'seer', 'cutract' ]\n",
    "model_name = 'ctgan_deep'  # synthetic data model\n",
    "\n",
    "p_train = 0.8  # proportion of training data for generative model. Default values if None\n",
    "n_models = 20  # number of models in ensemble, for each run\n",
    "max_n = 2000  # maximum number of data points to use for training generative model.\n",
    "nsyn = 2000  # number of synthetic data points per synthetic dataset. Defaults to same as generative training size if None\n",
    "\n",
    "num_runs = 10 # Number of runs. Don't choose to large, since total number of synthetic datasets is num_runs*n_models\n",
    "\n",
    "load = True  # results\n",
    "load_syn = True  # data\n",
    "save = True  # save results and data\n",
    "\n",
    "outlier = True\n",
    "\n",
    "verbose = False\n",
    "\n",
    "if nsyn is None:\n",
    "    nsyn = max_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: covid\n",
      "n_total 20000 n_train: 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [11:41<00:00,  2.85it/s]\n",
      "100%|██████████| 2000/2000 [10:56<00:00,  3.05it/s]\n",
      "100%|██████████| 2000/2000 [10:55<00:00,  3.05it/s]\n",
      " 65%|██████▍   | 1293/2000 [07:03<04:10,  2.82it/s]"
     ]
    }
   ],
   "source": [
    "for dataset in ['moons', 'circles']:\n",
    "    print('Dataset:', dataset)\n",
    "    workspace_folder, results_folder = get_folder_names(\n",
    "        dataset, model_name, max_n=max_n, nsyn=nsyn)\n",
    "\n",
    "    X_gt, X_syns = get_real_and_synthetic(dataset=dataset,\n",
    "                                          p_train=p_train,\n",
    "                                          n_models=num_runs*n_models,\n",
    "                                          model_name=model_name,\n",
    "                                          load_syn=load_syn,\n",
    "                                          verbose=verbose,\n",
    "                                          max_n=max_n,\n",
    "                                          nsyn=nsyn)\n",
    "\n",
    "    print('Shape of each synthetic dataset:', X_syns[0].shape)\n",
    "    print('Target type:', X_gt.targettype)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_total 10000 n_train: 2000\n",
      "Dataset moons\n",
      "\n",
      "\\begin{tabular}{lrrrrrrr}\n",
      "\\toprule\n",
      "{} &     AUC &     Acc &      F1 &  Precision &  Recall &     NLL &   Brier \\\\\n",
      "\\midrule\n",
      "DGE\\$\\_20\\$         &  0.9802 &  0.9177 &  0.9183 &     0.9122 &  0.9249 &  0.1979 &  0.0580 \\\\\n",
      "DGE\\$\\_10\\$         &  0.9796 &  0.9171 &  0.9176 &     0.9122 &  0.9232 &  0.1997 &  0.0588 \\\\\n",
      "DGE\\$\\_5\\$          &  0.9782 &  0.9140 &  0.9143 &     0.9131 &  0.9159 &  0.2053 &  0.0607 \\\\\n",
      "Naive (single)   &  0.9783 &  0.9164 &  0.9171 &     0.9115 &  0.9238 &  0.2023 &  0.0601 \\\\\n",
      "Naive (ensemble) &  0.9773 &  0.9145 &  0.9149 &     0.9084 &  0.9230 &  0.2060 &  0.0614 \\\\\n",
      "Oracle           &  0.9960 &  0.9693 &  0.9691 &     0.9699 &  0.9691 &  0.0848 &  0.0240 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "n_total 10000 n_train: 2000\n",
      "Dataset circles\n",
      "\n",
      "\\begin{tabular}{lrrrrrrr}\n",
      "\\toprule\n",
      "{} &     AUC &     Acc &      F1 &  Precision &  Recall &     NLL &   Brier \\\\\n",
      "\\midrule\n",
      "DGE\\$\\_20\\$         &  0.8654 &  0.7588 &  0.7233 &     0.8479 &  0.6311 &  0.5062 &  0.1673 \\\\\n",
      "DGE\\$\\_10\\$         &  0.8619 &  0.7579 &  0.7240 &     0.8409 &  0.6365 &  0.5064 &  0.1673 \\\\\n",
      "DGE\\$\\_5\\$          &  0.8536 &  0.7537 &  0.7218 &     0.8288 &  0.6397 &  0.5094 &  0.1688 \\\\\n",
      "Naive (single)   &  0.8040 &  0.7106 &  0.6748 &     0.7674 &  0.6065 &  0.5728 &  0.1931 \\\\\n",
      "Naive (ensemble) &  0.8039 &  0.7098 &  0.6737 &     0.7675 &  0.6048 &  0.5727 &  0.1929 \\\\\n",
      "Oracle           &  0.8680 &  0.7877 &  0.7888 &     0.7849 &  0.7926 &  0.4550 &  0.1470 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "n_total 32561 n_train: 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [12:09<00:00,  2.74it/s]\n",
      "100%|██████████| 2000/2000 [12:43<00:00,  2.62it/s]\n",
      "100%|██████████| 2000/2000 [12:45<00:00,  2.61it/s]\n",
      "100%|██████████| 2000/2000 [12:27<00:00,  2.67it/s]\n",
      "100%|██████████| 2000/2000 [12:41<00:00,  2.63it/s]\n",
      " 26%|██▌       | 517/2000 [03:16<09:24,  2.63it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[1;32m     11\u001b[0m     workspace_folder, results_folder \u001b[39m=\u001b[39m get_folder_names(\n\u001b[1;32m     12\u001b[0m         dataset, model_name, max_n\u001b[39m=\u001b[39mmax_n, nsyn\u001b[39m=\u001b[39mnsyn)\n\u001b[0;32m---> 14\u001b[0m     X_gt, X_syns \u001b[39m=\u001b[39m get_real_and_synthetic(dataset\u001b[39m=\u001b[39;49mdataset,\n\u001b[1;32m     15\u001b[0m                                           p_train\u001b[39m=\u001b[39;49mp_train,\n\u001b[1;32m     16\u001b[0m                                           n_models\u001b[39m=\u001b[39;49mn_models\u001b[39m*\u001b[39;49mnum_runs,\n\u001b[1;32m     17\u001b[0m                                           model_name\u001b[39m=\u001b[39;49mmodel_name,\n\u001b[1;32m     18\u001b[0m                                           load_syn\u001b[39m=\u001b[39;49mload_syn,\n\u001b[1;32m     19\u001b[0m                                           verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m     20\u001b[0m                                           max_n\u001b[39m=\u001b[39;49mmax_n,\n\u001b[1;32m     21\u001b[0m                                           nsyn\u001b[39m=\u001b[39;49mnsyn)\n\u001b[1;32m     22\u001b[0m     \u001b[39mif\u001b[39;00m X_gt\u001b[39m.\u001b[39mtargettype \u001b[39m!=\u001b[39m dataset_type:\n\u001b[1;32m     23\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/synthcity/DGE_data.py:185\u001b[0m, in \u001b[0;36mget_real_and_synthetic\u001b[0;34m(dataset, nsyn, p_train, n_models, model_name, load_syn, save, verbose, max_n)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mn_total\u001b[39m\u001b[39m'\u001b[39m, X_gt\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mn_train:\u001b[39m\u001b[39m'\u001b[39m, n_train)\n\u001b[1;32m    184\u001b[0m \u001b[39m# generate synthetic data for all number of training samples\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m X_syns \u001b[39m=\u001b[39m get_synthetic_data(X_gt, model_name,\n\u001b[1;32m    186\u001b[0m                             n_models\u001b[39m=\u001b[39;49mn_models,\n\u001b[1;32m    187\u001b[0m                             nsyn\u001b[39m=\u001b[39;49mnsyn,\n\u001b[1;32m    188\u001b[0m                             data_folder\u001b[39m=\u001b[39;49mdata_folder,\n\u001b[1;32m    189\u001b[0m                             load_syn\u001b[39m=\u001b[39;49mload_syn,\n\u001b[1;32m    190\u001b[0m                             save\u001b[39m=\u001b[39;49msave,\n\u001b[1;32m    191\u001b[0m                             verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m    193\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X_syns)):\n\u001b[1;32m    194\u001b[0m     X_syns[i]\u001b[39m.\u001b[39mdataset \u001b[39m=\u001b[39m dataset\n",
      "File \u001b[0;32m~/synthcity/DGE_data.py:123\u001b[0m, in \u001b[0;36mget_synthetic_data\u001b[0;34m(X_gt, model_name, n_models, nsyn, data_folder, load_syn, save, verbose)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[39mif\u001b[39;00m verbose:\n\u001b[1;32m    122\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mGenerating new data, filename is\u001b[39m\u001b[39m'\u001b[39m, filename)\n\u001b[0;32m--> 123\u001b[0m     X_syn \u001b[39m=\u001b[39m generate_synthetic(model_name, n_models, save, verbose, X_train, i, filename)\n\u001b[1;32m    125\u001b[0m X_syn \u001b[39m=\u001b[39m GenericDataLoader(X_syn[:nsyn], target_column\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    126\u001b[0m X_syn\u001b[39m.\u001b[39mtargettype \u001b[39m=\u001b[39m X_gt\u001b[39m.\u001b[39mtargettype\n",
      "File \u001b[0;32m~/synthcity/DGE_data.py:149\u001b[0m, in \u001b[0;36mgenerate_synthetic\u001b[0;34m(model_name, n_models, save, verbose, X_train, i, filename)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     syn_model \u001b[39m=\u001b[39m Plugins()\u001b[39m.\u001b[39mget(model_name)\n\u001b[0;32m--> 149\u001b[0m syn_model\u001b[39m.\u001b[39;49mfit(X_train)\n\u001b[1;32m    150\u001b[0m X_syn \u001b[39m=\u001b[39m syn_model\u001b[39m.\u001b[39mgenerate(count\u001b[39m=\u001b[39m\u001b[39m20000\u001b[39m) \u001b[39m# we won't need more in any experiment\u001b[39;00m\n\u001b[1;32m    152\u001b[0m         \u001b[39m# save X_syn to disk as pickle\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/test_env/lib/python3.8/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda/envs/test_env/lib/python3.8/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda/envs/test_env/lib/python3.8/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda/envs/test_env/lib/python3.8/site-packages/synthcity/plugins/core/plugin.py:183\u001b[0m, in \u001b[0;36mPlugin.fit\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m     X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompress_context \u001b[39m=\u001b[39m load_from_file(bkp_file)\n\u001b[1;32m    177\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_training_schema \u001b[39m=\u001b[39m Schema(\n\u001b[1;32m    178\u001b[0m     data\u001b[39m=\u001b[39mX,\n\u001b[1;32m    179\u001b[0m     sampling_strategy\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy,\n\u001b[1;32m    180\u001b[0m     random_state\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state,\n\u001b[1;32m    181\u001b[0m )\n\u001b[0;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda/envs/test_env/lib/python3.8/site-packages/synthcity/plugins/generic/plugin_ctgan.py:206\u001b[0m, in \u001b[0;36mCTGANPlugin._fit\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m     cond \u001b[39m=\u001b[39m kwargs[\u001b[39m\"\u001b[39m\u001b[39mcond\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    172\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m TabularGAN(\n\u001b[1;32m    173\u001b[0m     X\u001b[39m.\u001b[39mdataframe(),\n\u001b[1;32m    174\u001b[0m     n_units_latent\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerator_n_units_hidden,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    204\u001b[0m     device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice,\n\u001b[1;32m    205\u001b[0m )\n\u001b[0;32m--> 206\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(X\u001b[39m.\u001b[39;49mdataframe(), cond\u001b[39m=\u001b[39;49mcond)\n\u001b[1;32m    208\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/envs/test_env/lib/python3.8/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda/envs/test_env/lib/python3.8/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda/envs/test_env/lib/python3.8/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda/envs/test_env/lib/python3.8/site-packages/synthcity/plugins/core/models/tabular_gan.py:269\u001b[0m, in \u001b[0;36mTabularGAN.fit\u001b[0;34m(self, X, cond, fake_labels_generator, true_labels_generator, encoded)\u001b[0m\n\u001b[1;32m    267\u001b[0m extra_cond \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataloader_sampler\u001b[39m.\u001b[39mget_train_conditionals()\n\u001b[1;32m    268\u001b[0m cond \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_conditionals(cond, extra_cond)\n\u001b[0;32m--> 269\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    270\u001b[0m     np\u001b[39m.\u001b[39;49masarray(X_enc),\n\u001b[1;32m    271\u001b[0m     np\u001b[39m.\u001b[39;49masarray(cond),\n\u001b[1;32m    272\u001b[0m     fake_labels_generator\u001b[39m=\u001b[39;49mfake_labels_generator,\n\u001b[1;32m    273\u001b[0m     true_labels_generator\u001b[39m=\u001b[39;49mtrue_labels_generator,\n\u001b[1;32m    274\u001b[0m )\n\u001b[1;32m    275\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/envs/test_env/lib/python3.8/site-packages/synthcity/plugins/core/models/gan.py:236\u001b[0m, in \u001b[0;36mGAN.fit\u001b[0;34m(self, X, cond, fake_labels_generator, true_labels_generator)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    231\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpecting conditional with the same length as the dataset\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m         )\n\u001b[1;32m    234\u001b[0m     condt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_tensor(cond)\n\u001b[0;32m--> 236\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[1;32m    237\u001b[0m     Xt,\n\u001b[1;32m    238\u001b[0m     condt,\n\u001b[1;32m    239\u001b[0m     fake_labels_generator\u001b[39m=\u001b[39;49mfake_labels_generator,\n\u001b[1;32m    240\u001b[0m     true_labels_generator\u001b[39m=\u001b[39;49mtrue_labels_generator,\n\u001b[1;32m    241\u001b[0m )\n\u001b[1;32m    243\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/envs/test_env/lib/python3.8/site-packages/synthcity/plugins/core/models/gan.py:501\u001b[0m, in \u001b[0;36mGAN._train\u001b[0;34m(self, X, cond, fake_labels_generator, true_labels_generator)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[39m# Train loop\u001b[39;00m\n\u001b[1;32m    500\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerator_n_iter)):\n\u001b[0;32m--> 501\u001b[0m     g_loss, d_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_epoch(\n\u001b[1;32m    502\u001b[0m         loader,\n\u001b[1;32m    503\u001b[0m         fake_labels_generator\u001b[39m=\u001b[39;49mfake_labels_generator,\n\u001b[1;32m    504\u001b[0m         true_labels_generator\u001b[39m=\u001b[39;49mtrue_labels_generator,\n\u001b[1;32m    505\u001b[0m     )\n\u001b[1;32m    506\u001b[0m     \u001b[39m# Check how the generator is doing by saving G's output on fixed_noise\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     \u001b[39mif\u001b[39;00m (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_print \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda/envs/test_env/lib/python3.8/site-packages/synthcity/plugins/core/models/gan.py:454\u001b[0m, in \u001b[0;36mGAN._train_epoch\u001b[0;34m(self, loader, fake_labels_generator, true_labels_generator)\u001b[0m\n\u001b[1;32m    443\u001b[0m         X \u001b[39m=\u001b[39m data[\u001b[39m0\u001b[39m]\n\u001b[1;32m    445\u001b[0m     D_losses\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    446\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_epoch_discriminator(\n\u001b[1;32m    447\u001b[0m             X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    451\u001b[0m         )\n\u001b[1;32m    452\u001b[0m     )\n\u001b[1;32m    453\u001b[0m     G_losses\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 454\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_epoch_generator(\n\u001b[1;32m    455\u001b[0m             X,\n\u001b[1;32m    456\u001b[0m             cond,\n\u001b[1;32m    457\u001b[0m             fake_labels_generator\u001b[39m=\u001b[39;49mfake_labels_generator,\n\u001b[1;32m    458\u001b[0m             true_labels_generator\u001b[39m=\u001b[39;49mtrue_labels_generator,\n\u001b[1;32m    459\u001b[0m         )\n\u001b[1;32m    460\u001b[0m     )\n\u001b[1;32m    462\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean(G_losses), np\u001b[39m.\u001b[39mmean(D_losses)\n",
      "File \u001b[0;32m~/miniconda/envs/test_env/lib/python3.8/site-packages/synthcity/plugins/core/models/gan.py:310\u001b[0m, in \u001b[0;36mGAN._train_epoch_generator\u001b[0;34m(self, X, cond, fake_labels_generator, true_labels_generator)\u001b[0m\n\u001b[1;32m    307\u001b[0m noise \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(batch_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_units_latent, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    308\u001b[0m noise \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_optional_cond(noise, cond)\n\u001b[0;32m--> 310\u001b[0m fake_raw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerator(noise)\n\u001b[1;32m    311\u001b[0m fake \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_optional_cond(fake_raw, cond)\n\u001b[1;32m    313\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiscriminator(fake)\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/miniconda/envs/test_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda/envs/test_env/lib/python3.8/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda/envs/test_env/lib/python3.8/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda/envs/test_env/lib/python3.8/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda/envs/test_env/lib/python3.8/site-packages/synthcity/plugins/core/models/mlp.py:365\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[39m@validate_arguments\u001b[39m(config\u001b[39m=\u001b[39m\u001b[39mdict\u001b[39m(arbitrary_types_allowed\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n\u001b[1;32m    364\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, X: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m--> 365\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(X\u001b[39m.\u001b[39;49mfloat())\n",
      "File \u001b[0;32m~/miniconda/envs/test_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda/envs/test_env/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/envs/test_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda/envs/test_env/lib/python3.8/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda/envs/test_env/lib/python3.8/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda/envs/test_env/lib/python3.8/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda/envs/test_env/lib/python3.8/site-packages/synthcity/plugins/core/models/mlp.py:144\u001b[0m, in \u001b[0;36mMultiActivationHead.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    140\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape mismatch for the activations: expected \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39msum(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation_lengths)\u001b[39m}\u001b[39;00m\u001b[39m. Got shape \u001b[39m\u001b[39m{\u001b[39;00mX\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m     )\n\u001b[1;32m    143\u001b[0m split \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 144\u001b[0m out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mzeros(X\u001b[39m.\u001b[39;49mshape)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    146\u001b[0m \u001b[39mfor\u001b[39;00m activation, step \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivations, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation_lengths):\n\u001b[1;32m    147\u001b[0m     out[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, split : split \u001b[39m+\u001b[39m step] \u001b[39m=\u001b[39m activation(X[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, split : split \u001b[39m+\u001b[39m step])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from DGE_experiments import predictive_experiment\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "all_means = {}\n",
    "all_stds = {}\n",
    "dataset_type = 'classification'\n",
    "model_name = 'ctgan'\n",
    "\n",
    "for dataset in datasets:\n",
    "    workspace_folder, results_folder = get_folder_names(\n",
    "        dataset, model_name, max_n=max_n, nsyn=nsyn)\n",
    "\n",
    "    X_gt, X_syns = get_real_and_synthetic(dataset=dataset,\n",
    "                                          p_train=p_train,\n",
    "                                          n_models=n_models*num_runs,\n",
    "                                          model_name=model_name,\n",
    "                                          load_syn=load_syn,\n",
    "                                          verbose=verbose,\n",
    "                                          max_n=max_n,\n",
    "                                          nsyn=nsyn)\n",
    "    if X_gt.targettype != dataset_type:\n",
    "        continue\n",
    "\n",
    "    print(f'Dataset {dataset}\\n')\n",
    "\n",
    "    means, stds = predictive_experiment(X_gt,\n",
    "                                            X_syns,\n",
    "                                            workspace_folder=workspace_folder,\n",
    "                                            results_folder=results_folder,\n",
    "                                            save=save,\n",
    "                                            load=load,\n",
    "                                            plot=True,\n",
    "                                            outlier=outlier\n",
    "                                            )\n",
    "\n",
    "    print(means.to_latex())\n",
    "\n",
    "    all_means[dataset] = means\n",
    "    all_stds[dataset] = stds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrr}\n",
      "\\toprule\n",
      "{} &   AUC &   Acc &    F1 &  Precision &  Recall &   NLL &  Brier \\\\\n",
      "\\midrule\n",
      "DGE (k=10)              & 0.908 & 0.836 & 0.788 &      0.823 &   0.761 & 0.364 &  0.115 \\\\\n",
      "DGE (k=20)              & 0.910 & 0.836 & 0.786 &      0.826 &   0.756 & 0.363 &  0.115 \\\\\n",
      "DGE (k=5)               & 0.908 & 0.833 & 0.787 &      0.819 &   0.762 & 0.367 &  0.116 \\\\\n",
      "Naive (ensemble) max    & 0.908 & 0.843 & 0.804 &      0.856 &   0.835 & 0.453 &  0.146 \\\\\n",
      "Naive (ensemble) mean   & 0.892 & 0.819 & 0.767 &      0.799 &   0.745 & 0.392 &  0.125 \\\\\n",
      "Naive (ensemble) median & 0.897 & 0.822 & 0.773 &      0.803 &   0.748 & 0.384 &  0.123 \\\\\n",
      "Naive (ensemble) min    & 0.861 & 0.786 & 0.716 &      0.733 &   0.657 & 0.354 &  0.111 \\\\\n",
      "Naive (ensemble) std    & 0.014 & 0.016 & 0.025 &      0.035 &   0.051 & 0.028 &  0.010 \\\\\n",
      "Naive (single) max      & 0.908 & 0.843 & 0.804 &      0.855 &   0.839 & 0.456 &  0.146 \\\\\n",
      "Naive (single) mean     & 0.892 & 0.819 & 0.767 &      0.798 &   0.745 & 0.393 &  0.125 \\\\\n",
      "Naive (single) median   & 0.896 & 0.823 & 0.773 &      0.803 &   0.748 & 0.385 &  0.122 \\\\\n",
      "Naive (single) min      & 0.861 & 0.785 & 0.718 &      0.729 &   0.658 & 0.355 &  0.111 \\\\\n",
      "Naive (single) std      & 0.014 & 0.016 & 0.025 &      0.035 &   0.051 & 0.029 &  0.010 \\\\\n",
      "Oracle                  & 0.915 & 0.853 & 0.809 &      0.831 &   0.792 & 0.330 &  0.103 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "{} &  Moons &  Circles &  Adult Income &  SEER &  CUTRACT &  Mean \\\\\n",
      "\\midrule\n",
      "DGE (k=20)              &  0.981 &    0.863 &         0.893 & 0.907 &    0.907 & 0.910 \\\\\n",
      "DGE (k=10)              &  0.980 &    0.855 &         0.892 & 0.907 &    0.907 & 0.908 \\\\\n",
      "DGE (k=5)               &  0.979 &    0.863 &         0.887 & 0.907 &    0.906 & 0.908 \\\\\n",
      "Oracle                  &  0.996 &    0.868 &         0.889 & 0.911 &    0.911 & 0.915 \\\\\n",
      "Naive (single) median   &  0.980 &    0.825 &         0.867 & 0.904 &    0.904 & 0.896 \\\\\n",
      "Naive (single) mean     &  0.979 &    0.807 &         0.867 & 0.903 &    0.902 & 0.892 \\\\\n",
      "Naive (single) std      &  0.008 &    0.047 &         0.007 & 0.003 &    0.003 & 0.014 \\\\\n",
      "Naive (single) min      &  0.956 &    0.707 &         0.848 & 0.897 &    0.897 & 0.861 \\\\\n",
      "Naive (single) max      &  0.988 &    0.862 &         0.878 & 0.906 &    0.906 & 0.908 \\\\\n",
      "Naive (ensemble) median &  0.980 &    0.825 &         0.870 & 0.904 &    0.904 & 0.897 \\\\\n",
      "Naive (ensemble) mean   &  0.978 &    0.807 &         0.869 & 0.903 &    0.903 & 0.892 \\\\\n",
      "Naive (ensemble) std    &  0.008 &    0.047 &         0.007 & 0.003 &    0.003 & 0.014 \\\\\n",
      "Naive (ensemble) min    &  0.957 &    0.706 &         0.848 & 0.897 &    0.897 & 0.861 \\\\\n",
      "Naive (ensemble) max    &  0.988 &    0.862 &         0.878 & 0.906 &    0.906 & 0.908 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Moons</th>\n",
       "      <th>Circles</th>\n",
       "      <th>Adult Income</th>\n",
       "      <th>SEER</th>\n",
       "      <th>CUTRACT</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DGE (k=20)</th>\n",
       "      <td>0.981000</td>\n",
       "      <td>0.863000</td>\n",
       "      <td>0.893000</td>\n",
       "      <td>0.907000</td>\n",
       "      <td>0.907000</td>\n",
       "      <td>0.910200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DGE (k=10)</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.907000</td>\n",
       "      <td>0.907000</td>\n",
       "      <td>0.908200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DGE (k=5)</th>\n",
       "      <td>0.979000</td>\n",
       "      <td>0.863000</td>\n",
       "      <td>0.887000</td>\n",
       "      <td>0.907000</td>\n",
       "      <td>0.906000</td>\n",
       "      <td>0.908400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oracle</th>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.868000</td>\n",
       "      <td>0.889000</td>\n",
       "      <td>0.911000</td>\n",
       "      <td>0.911000</td>\n",
       "      <td>0.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive (single) median</th>\n",
       "      <td>0.980500</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.896200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive (single) mean</th>\n",
       "      <td>0.978750</td>\n",
       "      <td>0.806900</td>\n",
       "      <td>0.866900</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.902450</td>\n",
       "      <td>0.891500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive (single) std</th>\n",
       "      <td>0.008160</td>\n",
       "      <td>0.047436</td>\n",
       "      <td>0.006534</td>\n",
       "      <td>0.003058</td>\n",
       "      <td>0.003074</td>\n",
       "      <td>0.013652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive (single) min</th>\n",
       "      <td>0.956000</td>\n",
       "      <td>0.707000</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>0.897000</td>\n",
       "      <td>0.897000</td>\n",
       "      <td>0.861000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive (single) max</th>\n",
       "      <td>0.988000</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.906000</td>\n",
       "      <td>0.906000</td>\n",
       "      <td>0.908000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive (ensemble) median</th>\n",
       "      <td>0.980500</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.896700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive (ensemble) mean</th>\n",
       "      <td>0.978150</td>\n",
       "      <td>0.806650</td>\n",
       "      <td>0.869000</td>\n",
       "      <td>0.903000</td>\n",
       "      <td>0.902900</td>\n",
       "      <td>0.891940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive (ensemble) std</th>\n",
       "      <td>0.007863</td>\n",
       "      <td>0.047444</td>\n",
       "      <td>0.006731</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>0.002982</td>\n",
       "      <td>0.013600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive (ensemble) min</th>\n",
       "      <td>0.957000</td>\n",
       "      <td>0.706000</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>0.897000</td>\n",
       "      <td>0.897000</td>\n",
       "      <td>0.861000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive (ensemble) max</th>\n",
       "      <td>0.988000</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.906000</td>\n",
       "      <td>0.906000</td>\n",
       "      <td>0.908000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Moons   Circles  Adult Income      SEER   CUTRACT  \\\n",
       "DGE (k=20)               0.981000  0.863000      0.893000  0.907000  0.907000   \n",
       "DGE (k=10)               0.980000  0.855000      0.892000  0.907000  0.907000   \n",
       "DGE (k=5)                0.979000  0.863000      0.887000  0.907000  0.906000   \n",
       "Oracle                   0.996000  0.868000      0.889000  0.911000  0.911000   \n",
       "Naive (single) median    0.980500  0.825000      0.867500  0.904000  0.904000   \n",
       "Naive (single) mean      0.978750  0.806900      0.866900  0.902500  0.902450   \n",
       "Naive (single) std       0.008160  0.047436      0.006534  0.003058  0.003074   \n",
       "Naive (single) min       0.956000  0.707000      0.848000  0.897000  0.897000   \n",
       "Naive (single) max       0.988000  0.862000      0.878000  0.906000  0.906000   \n",
       "Naive (ensemble) median  0.980500  0.825000      0.870000  0.904000  0.904000   \n",
       "Naive (ensemble) mean    0.978150  0.806650      0.869000  0.903000  0.902900   \n",
       "Naive (ensemble) std     0.007863  0.047444      0.006731  0.002983  0.002982   \n",
       "Naive (ensemble) min     0.957000  0.706000      0.848000  0.897000  0.897000   \n",
       "Naive (ensemble) max     0.988000  0.862000      0.878000  0.906000  0.906000   \n",
       "\n",
       "                             Mean  \n",
       "DGE (k=20)               0.910200  \n",
       "DGE (k=10)               0.908200  \n",
       "DGE (k=5)                0.908400  \n",
       "Oracle                   0.915000  \n",
       "Naive (single) median    0.896200  \n",
       "Naive (single) mean      0.891500  \n",
       "Naive (single) std       0.013652  \n",
       "Naive (single) min       0.861000  \n",
       "Naive (single) max       0.908000  \n",
       "Naive (ensemble) median  0.896700  \n",
       "Naive (ensemble) mean    0.891940  \n",
       "Naive (ensemble) std     0.013600  \n",
       "Naive (ensemble) min     0.861000  \n",
       "Naive (ensemble) max     0.908000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_across_pandas(all_means)\n",
    "\n",
    "means_consolidated = metric_different_datasets(all_means)\n",
    "if num_runs>1:\n",
    "    stds_consolidated = metric_different_datasets(all_stds)\n",
    "    print(add_std(means_consolidated, stds_consolidated).to_latex())\n",
    "else:\n",
    "    print(means_consolidated.to_latex())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "We compare the single baseline model vs the generative uncertainty model vs an oracle. Workflow.\n",
    "0. Train and generate synthetic datasets $S_i$.\n",
    "1. Take each synthetic dataset $S_i$ and split it up in train and test.\n",
    "2. Train a model $f_i$ on the train set, for each $S_i$\n",
    "3. Evaluate on the same synthetic dataset's test set $S_{i,test}$, giving $\\hat{M}^S_i$ [Single performance]\n",
    "4. Evaluate on the true real test set (oracle), $D_{test}$, giving $M_i$ [Oracle performance]\n",
    "5. Evaluate on the other synthetic datasets $\\cup_{j\\neq i} S_{j}$, giving $\\hat{M}^G_i$ [Generative performance]\n",
    "6. Compute the deviation from the oracle, $||M_i - \\hat{M}_i||$ and average over all models $f_i$. \n",
    "7. Repeat 1-6 for different model classes $f$\n",
    "\n",
    "N.B. the idea of the above, is that the trained model $f_i$ is the same for each evaluation type. In the model selection section, we will compare the performance of different model classes, where we will train a new model for each evaluation type (hence the aim is to evaluate which class is best, while the model itself may vary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: moons\n",
      "n_total 10000 n_train: 5000\n",
      "Dataset: circles\n",
      "n_total 10000 n_train: 5000\n",
      "Dataset: adult\n",
      "n_total 32561 n_train: 5000\n",
      "Dataset: seer\n",
      "n_total 20000 n_train: 5000\n",
      "Dataset: cutract\n",
      "n_total 20000 n_train: 5000\n"
     ]
    }
   ],
   "source": [
    "from DGE_experiments import model_evaluation_experiment\n",
    "\n",
    "\n",
    "evaluation_means = {}\n",
    "evaluation_std = {}\n",
    "relative = False\n",
    "max_n = 5000\n",
    "nsyn = 5000\n",
    "model_name = 'ctgan_deep'\n",
    "datasets = ['moons', 'circles', 'adult', 'seer']\n",
    "\n",
    "for dataset in datasets:\n",
    "    print('Dataset:', dataset)\n",
    "    workspace_folder, results_folder = get_folder_names(\n",
    "        dataset, model_name, max_n=max_n, nsyn=nsyn)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # load data\n",
    "    X_gt, X_syns = get_real_and_synthetic(dataset=dataset,\n",
    "                                          p_train=p_train,\n",
    "                                          n_models=n_models,\n",
    "                                          model_name=model_name,\n",
    "                                          load_syn=load_syn,\n",
    "                                          verbose=verbose,\n",
    "                                          max_n=max_n,\n",
    "                                          nsyn=nsyn)\n",
    "\n",
    "    # get mean and std of dataset over different runs\n",
    "    means, std = model_evaluation_experiment(X_gt, X_syns, workspace_folder=workspace_folder, relative=relative,\n",
    "                                             model_type='deepish_mlp',\n",
    "                                             load=load,\n",
    "                                             save=load,\n",
    "                                             verbose=verbose,\n",
    "                                             outlier=outlier,\n",
    "                                             )\n",
    "\n",
    "    evaluation_means[dataset] = means\n",
    "    evaluation_std[dataset] = std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "{} &          Moons &        Circles &   Adult Income &           SEER &        CUTRACT &   Mean \\\\\n",
      "\\midrule\n",
      "Oracle     &   0.775 ± 0.14 &  0.508 ± 0.036 &  0.785 ± 0.015 &  0.711 ± 0.108 &  0.711 ± 0.108 &  0.698 \\\\\n",
      "Naive      &  0.892 ± 0.072 &  0.819 ± 0.132 &  0.784 ± 0.028 &  0.877 ± 0.061 &  0.877 ± 0.061 &   0.85 \\\\\n",
      "DGE (K=5)  &  0.703 ± 0.132 &   0.518 ± 0.07 &   0.773 ± 0.01 &  0.743 ± 0.129 &  0.743 ± 0.129 &  0.696 \\\\\n",
      "DGE (K=10) &  0.744 ± 0.139 &  0.522 ± 0.094 &   0.774 ± 0.01 &  0.772 ± 0.088 &  0.772 ± 0.088 &  0.717 \\\\\n",
      "DGE (K=20) &  0.753 ± 0.138 &  0.506 ± 0.045 &   0.775 ± 0.01 &  0.769 ± 0.069 &  0.769 ± 0.069 &  0.714 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mean across datasets\n",
    "# mean_across_pandas(evaluation_means)\n",
    "# per dataset\n",
    "metric = 'Acc'\n",
    "res = metric_different_datasets(evaluation_means, metric=metric, to_print=False)\n",
    "std_df = metric_different_datasets(evaluation_std, metric=metric, to_print=False)\n",
    "\n",
    "del std_df['Mean']\n",
    "res = add_std(res, std_df)\n",
    "if relative != 'l2':\n",
    "    print(res.to_latex(float_format=lambda x: '%.3f' % x))\n",
    "else:\n",
    "    print(res.to_latex(float_format=lambda x: '%.5f' % x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "Essentially repeat the above for different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_total 20000 n_train: 2000\n"
     ]
    }
   ],
   "source": [
    "from DGE_experiments import model_selection_experiment\n",
    "\n",
    "# load data\n",
    "max_n = 2000\n",
    "nsyn = 2000\n",
    "model_name = 'ctgan_deep'\n",
    "dataset = 'seer'\n",
    "X_gt, X_syns = get_real_and_synthetic(dataset=dataset,\n",
    "                                        p_train=p_train,\n",
    "                                        n_models=n_models,\n",
    "                                        model_name=model_name,\n",
    "                                        load_syn=load_syn,\n",
    "                                        verbose=verbose,\n",
    "                                        max_n=max_n,\n",
    "                                        nsyn=nsyn)\n",
    "\n",
    "if X_gt.targettype is not None:\n",
    "    if X_gt.targettype == 'classification':\n",
    "        metric = 'AUC'\n",
    "    elif X_gt.targettype == 'regression':\n",
    "        metric = 'MAE'\n",
    "\n",
    "    \n",
    "\n",
    "    workspace_folder, results_folder = get_folder_names(\n",
    "        dataset, model_name, max_n=max_n, nsyn=nsyn)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    means_sorted, std = model_selection_experiment(X_gt, X_syns, relative=False,\n",
    "                                                       workspace_folder=workspace_folder, \n",
    "                                                       load=load, save=save)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 deep_mlp    knn  xgboost     rf    svm     lr    mlp\n",
      "Oracle              0.860  0.864    0.868  0.873  0.874  0.894  0.897\n",
      "Naive               0.869  0.876    0.888  0.892  0.893  0.903  0.909\n",
      "DGE (K=5)           0.840  0.848    0.862  0.866  0.861  0.882  0.885\n",
      "DGE (K=10)          0.846  0.854    0.866  0.871  0.868  0.885  0.889\n",
      "DGE (K=20)          0.836  0.844    0.855  0.861  0.857  0.877  0.881\n",
      "Oracle rank         1.000  2.000    3.000  4.000  5.000  6.000  7.000\n",
      "Naive rank          1.000  2.000    3.000  4.000  5.000  6.000  7.000\n",
      "DGE (K=5) rank      1.000  2.000    4.000  5.000  3.000  6.000  7.000\n",
      "DGE (K=10) rank     1.000  2.000    3.000  5.000  4.000  6.000  7.000\n",
      "DGE (K=20) rank     1.000  2.000    3.000  5.000  4.000  6.000  7.000\n",
      "\\begin{tabular}{llllllll}\n",
      "\\toprule\n",
      "{} &       deep\\_mlp &            knn &        xgboost &             rf &            svm &             lr &            mlp \\\\\n",
      "\\midrule\n",
      "Oracle     &   0.86 ± 0.022 &  0.864 ± 0.018 &   0.868 ± 0.01 &   0.873 ± 0.01 &  0.874 ± 0.019 &  0.894 ± 0.008 &  0.897 ± 0.011 \\\\\n",
      "Naive      &  0.869 ± 0.035 &  0.876 ± 0.028 &  0.888 ± 0.027 &  0.892 ± 0.026 &  0.893 ± 0.023 &  0.903 ± 0.023 &  0.909 ± 0.022 \\\\\n",
      "DGE (K=5)  &   0.84 ± 0.017 &  0.848 ± 0.017 &  0.862 ± 0.008 &  0.866 ± 0.008 &  0.861 ± 0.022 &   0.882 ± 0.01 &  0.885 ± 0.009 \\\\\n",
      "DGE (K=10) &  0.846 ± 0.017 &  0.854 ± 0.016 &   0.866 ± 0.01 &  0.871 ± 0.008 &  0.868 ± 0.019 &  0.885 ± 0.011 &  0.889 ± 0.008 \\\\\n",
      "DGE (K=20) &  0.836 ± 0.018 &  0.844 ± 0.015 &   0.855 ± 0.01 &  0.861 ± 0.009 &  0.857 ± 0.018 &   0.877 ± 0.01 &  0.881 ± 0.008 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric = 'AUC'\n",
    "pickle.dump(means_sorted, open('seer_auc.p', 'wb'))\n",
    "print(means_sorted[metric])\n",
    "print(add_std(means_sorted[metric].iloc[:5], std[metric]).to_latex())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence of synthetic data size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's study the effect of synthetic data size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DGE_experiments import predictive_varying_nsyn\n",
    "\n",
    "predictive_varying_nsyn(X_gt, X_syns, dataset, model_name,\n",
    "                        nsyn, results_folder, workspace_folder, load=load, save=save, verbose=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density estimation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from DGE_experiments import density_experiment\n",
    "\n",
    "# if X_gt.targettype is None:\n",
    "#    density_experiment(X_gt, X_syns, load, save)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation\n",
    "\n",
    "We compare the single baseline model vs the generative uncertainty model. Single workflow\n",
    "1. Take each synthetic dataset $S_i$ and split it up in train and test.\n",
    "2. Train a model $f_i$ on the train set, for each $S_i$\n",
    "3. Evaluate on the same synthetic datasets test set $S_{i,test}$\n",
    "4. Evaluate on the true real test set (oracle), $D_{test}$, giving $\\hat{M}_i$\n",
    "5. Average results across the different synthetic datasets, giving $M_i$.\n",
    "6. Compute the deviation from the oracle, $||M_i - \\hat{M}_i||$ and average.\n",
    "\n",
    "Versus our baseline\n",
    "1. Take each synthetic dataset $S_i$ and split it up in train and test\n",
    "2. Train a model $f_i$ on the train set, for each $S_i$\n",
    "3. Evaluate on the same synthetic datasets test set $S_{i,test}\n",
    "4. Evaluate on the true real test set (oracle), $D_{test}$, giving $\\hat{M}_i$\n",
    "5. Average results across the different synthetic datasets, giving $M_i$.\n",
    "6. Compute the deviation from the oracle, $||M_i - \\hat{M}_i||$ and average.\n",
    "\n",
    "\n",
    "Cross-validation approach to test which type of model would perform best on real data. We compare the single baseline model vs the generative uncertainty model vs an oracle. Workflow Cross-validation.\n",
    "0. Train and generate synthetic datasets $S_i$.\n",
    "1. Use CV to train and evaluate models $f_i$ on each $S_i$. Repeat for all $S_i$. [Single performance]\n",
    "2. Use CV \\textit{over datasets $S_i$} (i.e. train on all but one $S_i$, evaluate on remaining and repeat) to train and evaluate models $f_i$.\n",
    "3. For both cases, evaluate the model also on the true real test set (oracle), $D_{test}$, giving $M_i$ [Oracle performance]\n",
    "4. Compute the deviation from the oracle, $||M_i - \\hat{M}_i||$ and average over all models $f_i$. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('test_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f2c99a57bac5efacecfbabca5467a1b952b0d9c1ae060d8550953085427f683"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
